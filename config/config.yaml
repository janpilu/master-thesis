model:
  name: "microsoft/deberta-v3-base"
  num_classes: 2
  freeze_bert: false
  classification_head:
    type: "mlp" # Options: simple, mlp, lstm
    input_dim: 768
    hidden_dim: 1536
    hidden_dim_2: 384
    dropout: 0.1

training:
  batch_size: 32
  learning_rate: 2e-5
  num_epochs: 30
  max_length: 128
  num_workers: 4
  early_stopping_patience: 10
  scheduler:
    type: "reduce_lr_on_plateau"
    mode: "min"
    factor: 0.1
    patience: 3

data:
  label_strategy: "toxicity_human"
  threshold: 3.0

paths:
  checkpoint_dir: "checkpoints"
  data_dir: "data"
  runs_dir: "runs"
