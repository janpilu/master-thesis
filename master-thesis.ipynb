{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\miniconda3\\envs\\master-thesis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from data.dataset import HateSpeechDataset\n",
    "from data.toxigen import ToxiGenDataModule, custom_label_strategy, human_threshold_strategy\n",
    "from models.model import HateSpeechClassifier\n",
    "from models.classification_heads import SimpleLinearHead, MLPHead\n",
    "from training.trainer import Trainer\n",
    "from utils.checkpoints import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use Config file for this step\n",
    "\n",
    "config = {\n",
    "        \"run_name\": \"mlp_head\",\n",
    "        \"model_name\": \"microsoft/deberta-v3-base\",\n",
    "        \"num_classes\": 2,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"num_epochs\": 1,\n",
    "        \"max_length\": 128,\n",
    "        \"num_workers\": 4,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\miniconda3\\envs\\master-thesis\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_module = ToxiGenDataModule(\n",
    "        tokenizer_name=config[\"model_name\"],\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        max_length=config[\"max_length\"],\n",
    "        label_strategy=human_threshold_strategy,\n",
    "        num_workers=config[\"num_workers\"],\n",
    "    )\n",
    "\n",
    "    # Setup datasets and get dataloaders\n",
    "data_module.setup()\n",
    "dataloaders = data_module.get_dataloaders()\n",
    "train_loader = dataloaders[\"train\"]\n",
    "val_loader = dataloaders[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head = MLPHead(\n",
    "        768, 1536, 384, config[\"num_classes\"]\n",
    "    )  # 768 is BERT's hidden size\n",
    "model = HateSpeechClassifier(\n",
    "        config[\"model_name\"], classification_head, freeze_bert=False\n",
    "    ).to(config[\"device\"])\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\miniconda3\\envs\\master-thesis\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from training.metrics import accuracy_metric, f1_metric\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy_metric,\n",
    "    'f1_score': f1_metric\n",
    "}\n",
    "\n",
    "# Initialize learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "        model=model, optimizer=optimizer, criterion=criterion, device=config[\"device\"],scheduler=scheduler,\n",
    "        metrics=metrics,\n",
    "        early_stopping_patience=7,\n",
    "        checkpoint_dir='checkpoints'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\dev\\master-thesis\\training\\trainer.py:111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import for path\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# # Train the model\n",
    "# history = trainer.train(\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     num_epochs=30,\n",
    "#     log_interval=1,\n",
    "# )\n",
    "\n",
    "# Load best checkpoint for inference\n",
    "best_checkpoint = list(Path('checkpoints').glob('best_model_*.pt'))[0]\n",
    "trainer.load_checkpoint(str(best_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint.save_checkpoint(\n",
    "#         model, optimizer, epoch, val_metrics[\"loss\"],{}, \"checkpoints\",config, config[\"run_name\"]\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint.load_checkpoint(\"checkpoints/checkpoint.pt\", model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\miniconda3\\envs\\master-thesis\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils.predictor import HateSpeechPredictor\n",
    "\n",
    "predictor = HateSpeechPredictor(model, config[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Where should i begin? I am so happy right now', 'prediction': 0, 'toxic_probability': 0.026428600773215294, 'non_toxic_probability': 0.9735714197158813}, {'text': 'I love you', 'prediction': 0, 'toxic_probability': 0.019253328442573547, 'non_toxic_probability': 0.9807466864585876}, {'text': 'I hate gays', 'prediction': 1, 'toxic_probability': 0.8715593814849854, 'non_toxic_probability': 0.12844060361385345}, {'text': 'I hate you', 'prediction': 1, 'toxic_probability': 0.9498029947280884, 'non_toxic_probability': 0.050196945667266846}, {'text': 'Black people are the worst', 'prediction': 1, 'toxic_probability': 0.9802342057228088, 'non_toxic_probability': 0.019765831530094147}]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Where should i begin? I am so happy right now\", \"I love you\", \"I hate gays\", \"I hate you\", \"Black people are the worst\"] \n",
    "prediction = predictor.predict(texts)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'We should help africa', 'prediction': 0, 'toxic_probability': 0.22286871075630188, 'non_toxic_probability': 0.7771313190460205}, {'text': 'Why should we help Africa', 'prediction': 0, 'toxic_probability': 0.35938793420791626, 'non_toxic_probability': 0.6406120657920837}, {'text': 'Why should we help Africa, we shouldnt encourage begging', 'prediction': 1, 'toxic_probability': 0.8812673091888428, 'non_toxic_probability': 0.11873272061347961}, {'text': 'Despite their culture being that of apes some africans are really kind', 'prediction': 1, 'toxic_probability': 0.7226390242576599, 'non_toxic_probability': 0.2773609459400177}, {'text': 'I would never say nigger', 'prediction': 0, 'toxic_probability': 0.4120437204837799, 'non_toxic_probability': 0.5879563093185425}]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"We should help africa\", \"Why should we help Africa\", \"Why should we help Africa, we shouldnt encourage begging\"] \n",
    "prediction = predictor.predict(texts)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'I would never say nigger', 'prediction': 0, 'toxic_probability': 0.4120437204837799, 'non_toxic_probability': 0.5879563093185425}, {'text': 'I would never say nigger nigger', 'prediction': 0, 'toxic_probability': 0.4200800955295563, 'non_toxic_probability': 0.5799199342727661}, {'text': 'I would never say nigger nigger nigger', 'prediction': 0, 'toxic_probability': 0.41566675901412964, 'non_toxic_probability': 0.5843332409858704}]\n"
     ]
    }
   ],
   "source": [
    "texts = [ \"I would never say nigger\", \"I would never say nigger nigger\",  \"I would never say nigger nigger nigger\"] \n",
    "prediction = predictor.predict(texts)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Jews love nature', 'prediction': 0, 'toxic_probability': 0.009527722373604774, 'non_toxic_probability': 0.9904723167419434}, {'text': 'Jews love money', 'prediction': 1, 'toxic_probability': 0.8688678741455078, 'non_toxic_probability': 0.13113218545913696}, {'text': 'Jews love coins', 'prediction': 0, 'toxic_probability': 0.17644533514976501, 'non_toxic_probability': 0.8235546946525574}, {'text': 'Jews love value', 'prediction': 0, 'toxic_probability': 0.039441220462322235, 'non_toxic_probability': 0.9605587720870972}, {'text': 'Jews love to be valued', 'prediction': 0, 'toxic_probability': 0.02172423154115677, 'non_toxic_probability': 0.9782757759094238}]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Jews love nature\", \"Jews love money\", \"Jews love coins\", \"Jews love value\", \"Jews love to be valued\"] \n",
    "prediction = predictor.predict(texts)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'The Holocaust happened', 'prediction': 0, 'toxic_probability': 0.010812245309352875, 'non_toxic_probability': 0.9891877770423889}, {'text': 'The Holocaust did not happen', 'prediction': 0, 'toxic_probability': 0.074808269739151, 'non_toxic_probability': 0.9251917600631714}, {'text': 'The Holocaust did not not happen', 'prediction': 0, 'toxic_probability': 0.056685030460357666, 'non_toxic_probability': 0.9433150291442871}, {'text': 'Yeah  right, The Holocaust happened', 'prediction': 0, 'toxic_probability': 0.3381359875202179, 'non_toxic_probability': 0.6618639826774597}]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"The Holocaust happened\", \"The Holocaust did not happen\",\"The Holocaust did not not happen\",\"Yeah  right, The Holocaust happened\"] \n",
    "prediction = predictor.predict(texts)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing', 'predicted_group', 'stereotyping', 'intent', 'toxicity_ai', 'toxicity_human', 'predicted_author', 'actual_method'],\n",
       "    num_rows: 8960\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.toxigen import ToxiGenDataset\n",
    "\n",
    "\n",
    "ds=ToxiGenDataset(\"train\",config[\"model_name\"])\n",
    "ds.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
